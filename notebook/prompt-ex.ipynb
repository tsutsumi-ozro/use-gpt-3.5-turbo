{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file to pdf_files/language_understanding_paper.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_url = 'https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf'\n",
    "r = requests.get(pdf_url)\n",
    "if r.status_code != 200:\n",
    "    raise ValueError(\n",
    "        'Check the URL of your file; returned status code: %s' % r.status_code\n",
    "    )\n",
    "\n",
    "parsed_url = urlparse(pdf_url)\n",
    "file_name = os.path.basename(parsed_url.path)\n",
    "\n",
    "pdf_file_dir = Path('pdf_files')\n",
    "pdf_file_dir.mkdir(exist_ok=True)\n",
    "file_path = pdf_file_dir / file_name\n",
    "\n",
    "with open(file_path, 'wb') as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "print('Saved file to %s' % file_path)\n",
    "\n",
    "from pdfminer.high_level import extract_text\n",
    "text = extract_text(str(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字か数字かを判定. 数字の場合はTrueを返す\n",
    "def is_digit_or_uppercase_word(element):\n",
    "    if element.isdigit() or element[0].isupper():\n",
    "        return True\n",
    "    return False\n",
    "chunk_idx = []\n",
    "chunk_key_names = []\n",
    "for idx, chunk in enumerate(text.split('\\n\\n')):\n",
    "    chunk_elements = chunk.split()\n",
    "    chunk_judgement = [is_digit_or_uppercase_word(element) for element in chunk_elements]\n",
    "    if all(chunk_judgement):\n",
    "        if len(chunk) > 3:\n",
    "            # print(chunk)\n",
    "            # print('chunk_idx:',idx)\n",
    "            chunk_idx.append(idx)\n",
    "            chunk_key_names.append(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_dict = dict()\n",
    "\n",
    "for idx, chunk_key_name in enumerate(chunk_key_names):\n",
    "    if idx == len(chunk_key_names)-1:\n",
    "        chunk_dict[chunk_key_name] = (chunk_idx[idx], len(text.split('\\n\\n')))\n",
    "    else:\n",
    "        chunk_dict[chunk_key_name] = (chunk_idx[idx], chunk_idx[idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abstract': (5, 8),\n",
       " 'Introduction': (8, 16),\n",
       " '2 Related Work': (16, 24),\n",
       " '3 Framework': (24, 57),\n",
       " '4 Experiments': (57, 62),\n",
       " 'Task': (62, 63),\n",
       " 'Datasets': (63, 76),\n",
       " 'Method': (177, 178),\n",
       " 'MNLI-m MNLI-mm SNLI': (77, 78),\n",
       " 'SciTail QNLI RTE': (78, 106),\n",
       " 'Story Cloze RACE-m RACE-h RACE': (107, 128),\n",
       " 'Classiﬁcation': (129, 130),\n",
       " 'Semantic Similarity': (130, 131),\n",
       " 'GLUE': (131, 171),\n",
       " '5 Analysis': (171, 177),\n",
       " 'Avg. Score': (178, 209),\n",
       " '6 Conclusion': (209, 211),\n",
       " 'References': (211, 332)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "section = dict()\n",
    "for chunk_key_name in chunk_dict.keys():\n",
    "    sentences = text.split('\\n\\n')[chunk_dict[chunk_key_name][0]+1 :chunk_dict[chunk_key_name][1]]\n",
    "    sentences = ''.join(sentences)\n",
    "    sentences = sentences.replace('\\n','')\n",
    "    section[chunk_key_name] = sentences"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**temperature**<br>\n",
    "あくまで、LLMは次に来る単語を予測するモデル.<br>\n",
    "temperatureを変更することで、予測される単語の多様性を変更できる.<br>\n",
    "\n",
    "temperatureが0だと、常に一番高い確率のものを選択し続ける. 1に近づくにつれリスクを取り、確率の低い単語も選択し、多様性が増す.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Orange who?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temperatureは確信度を表すパラメータ\n",
    "# 0に近いほど確信度が高くなる(回答が固定される)\n",
    "# 1に近いほど確信度が低くなる(回答がランダムになる)\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "MODEL = \"gpt-3.5-turbo\"\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {'role': \"system\", 'content': 'You are a helpful assistant'},\n",
    "        {'role': \"user\", 'content': 'Knock knock'},\n",
    "        {'role': 'assistant', 'content': 'Who\\'s there?'},\n",
    "        {'role': \"user\", 'content': 'Orange'}\n",
    "    ],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
